# Investigations

These investigation presentations aim to introduce you to interesting applications and sub-topics of machine learning and data science more broadly. You will research and present briefly on your topic, becoming a relative expert. Your classmates will research and present on their topics so that you may learn from them. This process should expand your appreciation of various ways that data science is applied and help you to think about ways that you can apply what you're learning for your final project.

You can choose from the starter list of topics below, or choose an application that you discover independently, as long as you don't duplicate anyone else's topic. The links included with the starter list represent a starting point - often you'll be able to find much more if you are interested.

Your presentation should be roughly five minutes long, light weight in terms of setup and tear-down, and hopefully interesting. You will likely want to include:

 * Who is involved? (A person? A company?)
 * What is the problem that's being addressed?
 * What data is available, being used, or relevant for a technique?
 * What techniques are being developed/applied?
 * How does the application relate to other topics of the class?
 * How does the application relate to the world? What are the implications? (Opportunities? Risks?)

Application Presentations will be delivered daily at 1:30, so be sure to be prepared for yours!

How do you know you're done?

 * You have delivered your presentation to the class.
 * You have a set of slides (and/or other materials) for your presentation.
 * You have submitted a pull request to this repo/directory with a subdirectory containing your materials and/or links to your materials.  Your file should be **PDF** format so it can be viewable on GitHub.


## Topics for Investigation

The best topic for you is _the one you choose yourself_. You can add to this list!


Software / Systems:

 * Dat [1](http://dat-data.com/)
 * Blaze [1](http://continuum.io/blog/blaze-expressions)
 * Luigi [1](https://github.com/spotify/luigi)
 * Docker [1](https://www.docker.com/)
 * Ferry [1](http://ferry.opencore.io/en/latest/) (Hadoop with Docker)
 * Amazon Machine Learning [1](http://aws.amazon.com/machine-learning/)
 * Azure Machine Learning [1](http://azure.microsoft.com/en-us/services/machine-learning/)
 * Huginn [1](https://github.com/cantino/huginn)
 * Datomic [1](http://www.datomic.com/)
 * Dynamo [1](http://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf) [2](http://aws.amazon.com/dynamodb/)


Methods:

 * Topological Data Analysis [[1]](http://normaldeviate.wordpress.com/2012/07/01/topological-data-analysis/) [[2]](http://www.cs.dartmouth.edu/~afra/papers/ams12/tda.pdf) [[3]](http://www.nature.com/srep/2013/130207/srep01236/full/srep01236.html) [[4]](https://www.youtube.com/watch?v=XfWibrh6stw) [[5]](http://www.ayasdi.com/resources/) [[6]](http://web.cse.ohio-state.edu/~tamaldey/course/CTDA/CTDA.html)
 * Google PageRank [[1]](http://www.nybooks.com/articles/archives/2011/aug/18/how-google-dominates-us/) [[2]](http://en.wikipedia.org/wiki/PageRank)
 * Sorting intelligently based on ratings [[1]](http://www.evanmiller.org/how-not-to-sort-by-average-rating.html)


Applications:

 * The Netflix Prize [[1]](http://en.wikipedia.org/wiki/Netflix_Prize)
 * Facebook Immune System [[1]](http://research.microsoft.com/en-us/projects/ldg/a10-stein.pdf)
 * Amazon anticipatory ordering [[1]](http://www.usatoday.com/story/money/business/2014/01/18/amazon-anticipates-orders/4637895/)
 * Foursquare point assignment [[1]](http://engineering.foursquare.com/2014/01/03/the-mathematics-of-gamification/)
 * Predicting crime and criminality [[1]](http://www.npr.org/2011/11/26/142758000/at-lapd-predicting-crimes-before-they-happen) [[2]](http://www.bloomberg.com/news/2013-08-14/how-big-data-could-help-identify-the-next-felon-or-blame-the-wrong-guy.html)
 * Identifying suicide risk of military service members [[1]](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0085733)
 * Winning the Kaggle Web Search Challenge [[1]](http://blog.kaggle.com/2014/02/06/winning-personalized-web-search-team-dataiku/)
 * Data mining for dating on OkCupid [[1]](http://www.wired.com/wiredscience/2014/01/how-to-hack-okcupid/all/)
 * Predicting music rankings [[1]](http://www.itnews.com.au/News/370073,warmest-100-is-back-with-new-bag-of-tricks.aspx)
 * Winning the Kaggle Amazon Access Challenge [[1]](http://blog.kaggle.com/2013/08/29/qa-with-amazon-access-challenge-first-prize-winner-paul-duan/)
 * Mortar Data infrastructure on AWS [[1]](http://aws.amazon.com/solutions/case-studies/mortar-data/)
 * Ranking the web [[1]](http://search.slashdot.org/story/14/02/12/1651243/the-first-open-ranking-of-the-world-wide-web-is-available)
 * Ancestry and Genetics from 23andme [[1]](http://blog.23andme.com/ancestry/23andmes-newest-feature-explores-your-ancestry/)
 * Music recommendations at Spotify [[1]](http://www.slideshare.net/erikbern/collaborative-filtering-at-spotify-16182818)
 * Microsoft fighting Skype fraud [[1]](http://www.cso.com.au/article/536286/new_research_signals_trouble_skype_fraudsters/) [[2]](http://research.microsoft.com/pubs/205472/aisec10-leontjeva.pdf)
 * Computerized essay grading [[1]](http://www.nytimes.com/2013/04/05/science/new-test-for-computers-grading-essays-at-college-level.html)
 * Using deep learning to listen for whales [[1]](http://danielnouri.org/notes/2014/01/10/using-deep-learning-to-listen-for-whales/)
 * Global food prices and unrest [[1]](http://motherboard.vice.com/blog/a-complex-systems-model-predicted-the-revolutions-sweeping-the-globe-right) [[2]](http://necsi.edu/research/social/foodprices/update/)
 * The Science of Singing Along [[1]](http://www.doc.gold.ac.uk/~mas03dm/papers/PawleyMullensiefen_Singalong_2012.pdf)
 * Double Entendre Identification [[1]](http://aclweb.org/anthology//P/P11/P11-2016.pdf)
 * Generating jokes from data [[1]](http://homepages.inf.ed.ac.uk/s0894589/petrovic13unsupervised.pdf)
 * Analyzing and predicting YouTube comments [[1]](http://www.l3s.de/~siersdorfer/sources/2010/wfp0542-siersdorfer.pdf)
 * Winning the Galaxy Zoo Challenge on Kaggle [[1]](http://blog.kaggle.com/2014/04/18/winning-the-galaxy-challenge-with-convnets/) [[2]](http://benanne.github.io/2014/04/05/galaxy-zoo.html) [[3]](http://www.kaggle.com/c/galaxy-zoo-the-galaxy-challenge/forums/t/7599/so-what-were-your-approaches)
 * Winning the March Machine Learning Mania on Kaggle [[1]](http://blog.kaggle.com/2014/04/21/qa-with-gregory-and-michael-1st-place-in-march-ml-mania/) [[2]](https://www.kaggle.com/c/march-machine-learning-mania/forums/t/7637/end-of-competition-thread)
 * Event Recommendation Challenge on Kaggle [[1]](http://blog.kaggle.com/2013/02/25/5-lessons-learned-for-the-event-recommendation-challenge/) [[2]](http://www.kaggle.com/c/event-recommendation-engine-challenge/forums/t/3894/solutions/20972)
 * The Importance of Reproducible Research in High-Throughput Biology (Duke cancer treatment scandal) [[1]](http://www.economist.com/node/21528593) [[2]](http://www.cbsnews.com/news/deception-at-duke-fraud-in-cancer-care/) [[3]](https://www.youtube.com/watch?v=7gYIs7uYbMo) [[4]](http://www.dataschool.io/reproducibility-is-not-just-for-researchers/)
